{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia detection based on Chest X-Ray images on imbalanced data using tensorflow transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original notebook can be found here https://www.kaggle.com/michalbrezk/x-ray-pneumonia-cnn-tensorflow-2-0-keras-94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use tensorflow to load and pre-process X-Ray images of chest and apply Keras CNN model on these data. Dataset is imbalanced (approx. 1:3), images may have different site and can have one or 3 color channels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 3 folders - train, test, val. Train & test are used for modeling, validation will be used to check performance of model. Size of validation set is very small (16 cases).\n",
    "\n",
    "Each folder contains PNEUMONIA and NORMAL sub-folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../chest_xray/'\n",
    "\n",
    "val_dir = path+'val'\n",
    "test_dir = path+'test'\n",
    "train_dir = path+'train'\n",
    "\n",
    "img_height = 196\n",
    "img_width = 196\n",
    "image_size =(img_height, img_width)\n",
    "\n",
    "class_name = {\"0\":\"NORMAL\",\"1\":\"PNEUMONIA\"}\n",
    "\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------train files-----------------\n",
      "Found 5216 files belonging to 2 classes.\n",
      "---------------test files-----------------\n",
      "Found 624 files belonging to 2 classes.\n",
      "---------------validation files-----------------\n",
      "Found 16 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------train files-----------------\")\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir, labels='inferred', label_mode='binary',class_names=[\"NORMAL\",\"PNEUMONIA\"], color_mode='grayscale',\n",
    "    batch_size=batch_size, image_size=image_size, shuffle=True, seed=0, validation_split=None, subset=None)\n",
    "\n",
    "print(\"---------------test files-----------------\")\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir, labels='inferred', label_mode='binary',class_names=[\"NORMAL\",\"PNEUMONIA\"], color_mode='grayscale',\n",
    "    batch_size=batch_size, image_size=image_size, shuffle=True, seed=0, validation_split=None, subset=None)\n",
    "\n",
    "print(\"---------------validation files-----------------\")\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir, labels='inferred', label_mode='binary',class_names=[\"NORMAL\",\"PNEUMONIA\"], color_mode='grayscale',\n",
    "    batch_size=batch_size, image_size=image_size, shuffle=True, seed=0, validation_split=None, subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 196, 196, 1)\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_data:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "train = train_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(train))\n",
    "first_image = image_batch[0]\n",
    "\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "test = test_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "val = val_data.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.concatenate([y for x , y in train], axis=0)\n",
    "X_train = np.concatenate([x for x , y in train], axis=0)\n",
    "\n",
    "Y_test = np.concatenate([y for x , y in test], axis=0)\n",
    "X_test = np.concatenate([x for x , y in test], axis=0)\n",
    "\n",
    "Y_val = np.concatenate([y for x , y in val], axis=0)\n",
    "X_val = np.concatenate([x for x , y in val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)\n",
    "y_val = to_categorical(Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define generator\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model_builder():\n",
    "    \"\"\"Build a keras model for image classification on cifar10 dataset.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu',\n",
    "                               input_shape=(196, 196, 1), name='img_raw_xf'),\n",
    "        tf.keras.layers.Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
    "     \n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),        \n",
    "      \n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(2, activation='softmax')\n",
    "        \n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=0.0001, decay=1e-5),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1304/1304 [==============================] - 605s 462ms/step - loss: 1.0057 - accuracy: 0.2648 - val_loss: 1.0521 - val_accuracy: 0.3750\n",
      "Epoch 2/50\n",
      "1304/1304 [==============================] - 651s 499ms/step - loss: 0.9488 - accuracy: 0.2541 - val_loss: 1.0372 - val_accuracy: 0.3750\n",
      "Epoch 3/50\n",
      " 289/1304 [=====>........................] - ETA: 8:19 - loss: 0.9631 - accuracy: 0.2645"
     ]
    }
   ],
   "source": [
    "model = keras_model_builder()\n",
    "\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint('../models/pneu_detect_tf_model.hdf5', \n",
    "                                                monitor='val_acc', verbose=0, \n",
    "                                                save_best_only=True, \n",
    "                                                save_weights_only=False, \n",
    "                                                mode='auto')\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "\n",
    "history = model.fit(datagen.flow(X_train,y_train, batch_size=32), validation_data=(X_test, y_test),\n",
    "                    epochs = 5, verbose = 1, callbacks=[callback], class_weight={0:6.0, 1:0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfx-tunnel]",
   "language": "python",
   "name": "conda-env-tfx-tunnel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
