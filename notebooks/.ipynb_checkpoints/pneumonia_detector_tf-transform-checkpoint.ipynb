{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia detection based on Chest X-Ray images on imbalanced data using tensorflow transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original notebook can be found here https://www.kaggle.com/michalbrezk/x-ray-pneumonia-cnn-tensorflow-2-0-keras-94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use tensorflow to load and pre-process X-Ray images of chest and apply Keras CNN model on these data. Dataset is imbalanced (approx. 1:3), images may have different site and can have one or 3 color channels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 3 folders - train, test, val. Train & test are used for modeling, validation will be used to check performance of model. Size of validation set is very small (16 cases).\n",
    "\n",
    "Each folder contains PNEUMONIA and NORMAL sub-folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../chest_xray/'\n",
    "\n",
    "val_dir = path+'val'\n",
    "test_dir = path+'test'\n",
    "train_dir = path+'train'\n",
    "\n",
    "img_height = 196\n",
    "img_width = 196\n",
    "image_size =(img_height, img_width)\n",
    "\n",
    "class_name = {\"0\":\"NORMAL\",\"1\":\"PNEUMONIA\"}\n",
    "\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------train files-----------------\n",
      "Found 5216 files belonging to 2 classes.\n",
      "---------------test files-----------------\n",
      "Found 624 files belonging to 2 classes.\n",
      "---------------validation files-----------------\n",
      "Found 16 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------train files-----------------\")\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir, labels='inferred', label_mode='binary',class_names=[\"NORMAL\",\"PNEUMONIA\"], color_mode='grayscale',\n",
    "    batch_size=batch_size, image_size=image_size, shuffle=True, seed=0, validation_split=None, subset=None)\n",
    "\n",
    "print(\"---------------test files-----------------\")\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir, labels='inferred', label_mode='binary',class_names=[\"NORMAL\",\"PNEUMONIA\"], color_mode='grayscale',\n",
    "    batch_size=batch_size, image_size=image_size, shuffle=True, seed=0, validation_split=None, subset=None)\n",
    "\n",
    "print(\"---------------validation files-----------------\")\n",
    "val_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir, labels='inferred', label_mode='binary',class_names=[\"NORMAL\",\"PNEUMONIA\"], color_mode='grayscale',\n",
    "    batch_size=batch_size, image_size=image_size, shuffle=True, seed=0, validation_split=None, subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 196, 196, 1)\n",
      "(32, 1)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_data:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "train = train_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(train))\n",
    "first_image = image_batch[0]\n",
    "\n",
    "# Notice the pixels values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))\n",
    "\n",
    "test = test_data.map(lambda x, y: (normalization_layer(x), y))\n",
    "val = val_data.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.concatenate([y for x , y in train], axis=0)\n",
    "X_train = np.concatenate([x for x , y in train], axis=0)\n",
    "\n",
    "Y_test = np.concatenate([y for x , y in test], axis=0)\n",
    "X_test = np.concatenate([x for x , y in test], axis=0)\n",
    "\n",
    "Y_val = np.concatenate([y for x , y in val], axis=0)\n",
    "X_val = np.concatenate([x for x , y in val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (5216, 196, 196, 1), Labels shape: (5216, 1)\n",
      "Test data shape: (624, 196, 196, 1), Labels shape: (624, 1)\n",
      "Validation data shape: (16, 196, 196, 1), Labels shape: (16, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape: {}, Labels shape: {}'.format(X_train.shape, Y_train.shape))\n",
    "print('Test data shape: {}, Labels shape: {}'.format(X_test.shape, Y_test.shape))\n",
    "print('Validation data shape: {}, Labels shape: {}'.format(X_val.shape, Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.squeeze()\n",
    "Y_test = Y_test.squeeze()\n",
    "Y_val = Y_val.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (5216, 196, 196, 1), Labels shape: (5216,)\n",
      "Test data shape: (624, 196, 196, 1), Labels shape: (624,)\n",
      "Validation data shape: (16, 196, 196, 1), Labels shape: (16,)\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape: {}, Labels shape: {}'.format(X_train.shape, Y_train.shape))\n",
    "print('Test data shape: {}, Labels shape: {}'.format(X_test.shape, Y_test.shape))\n",
    "print('Validation data shape: {}, Labels shape: {}'.format(X_val.shape, Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)\n",
    "y_val = to_categorical(Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu', input_shape=(196, 196, 1)))\n",
    "model.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.0001, decay=1e-5)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1304/1304 [==============================] - 528s 404ms/step - loss: 1.0152 - accuracy: 0.2830 - val_loss: 1.0524 - val_accuracy: 0.3750\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Epoch 2/2\n",
      "1304/1304 [==============================] - 537s 412ms/step - loss: 0.9483 - accuracy: 0.2525 - val_loss: 1.1276 - val_accuracy: 0.3750\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saveBestModel = keras.callbacks.ModelCheckpoint('../models/pneu_detect_cnn-keras_model.hdf5', \n",
    "                                                monitor='val_acc', verbose=0, \n",
    "                                                save_best_only=True, \n",
    "                                                save_weights_only=False, \n",
    "                                                mode='auto')\n",
    "\n",
    "callback = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "history = model.fit(datagen.flow(X_train,y_train, batch_size=4), validation_data=(X_test, y_test), epochs = 2, verbose = 1,\n",
    "                    callbacks=[saveBestModel,callback], class_weight={0:6.0, 1:0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfx-tunnel]",
   "language": "python",
   "name": "conda-env-tfx-tunnel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
